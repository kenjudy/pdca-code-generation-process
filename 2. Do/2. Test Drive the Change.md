# Implementation Phase: TDD Execution

**Purpose:** Execute planned changes using strict Test-Driven Development discipline
**When to use:** After completing planning phase, for each implementation step
**Prerequisites:** Detailed implementation plan with atomic steps defined
**Expected output:** Working, tested code changes following red-green-refactor cycle
**Typical duration:** Variable (15 minutes to several hours depending on scope)
**Next step:** Completeness check (3) when all planned steps complete
**Critical:** Human must intervene immediately when TDD discipline breaks

---
```markdown
	Test suite is in NUnit with Assert.That syntax with heavy reliance on TestUtils.cs and the fixtures directory to avoid mocking.

	**TDD Implementation**
	
	1. ‚ùå DON'T test interfaces - test concrete implementations
	2. ‚ùå DON'T use compilation errors as RED phase - use behavioral failures  
	3. ‚úÖ DO create stub implementations that compile but fail behaviorally
	4. ‚úÖ DO use real components over mocks when possible
	   
	   THIS MEANS: Compilation errors are not a valid red. A red test is when an invocation does not meet the expectation. So, that would imply the project can compile and the method stubs exist but the behavior is not fully implemented.
	
	**üö® TDD DISCIPLINE CHECK üö®**
	- [ ] Have I written a FAILING test first? (RED phase mandatory)
	- [ ] Am I implementing ONLY enough to make the test pass? (GREEN phase)
	- [ ] Is this test simple enough? (Complex scenarios ‚Üí simplify first)
	- [ ] Am I using mocks when I should be using real components
	- [ ] Did I check how existing code handles this pattern?
	
	**Integration Tests & Real-World Validation**
	- [ ] Default to real components + temporary resources
	- [ ] Question complex mocking: Ask "Why not use real File access with temporary directories?"
	- [ ] **CRITICAL**: Before implementing any external system integration, inspect actual system behavior/outputs first
	- [ ] Build end-to-end scaffolding early, not as an afterthought
	- [ ] Test against real data/systems before optimizing unit tests
	
	**AI Command Transparency:**
	
	- [ ] Show reasoning, particularly when you need to deviate from plan.
	
	**Current step:** 
	**Red phase:** Write the failing test first (NO exceptions)
	**Green phase:** Make it pass with minimal code
	**Refactor:** Clean up if needed
	
	**Test Complexity Management:**
	- Start with single-file, basic scenarios
	- Avoid multi-file compilations initially
	- If test setup gets complex, simplify the scenario
	- Build complexity gradually in subsequent iterations
	
	**Ready for commit?** 
	- [ ] Test written and failing first ‚úÖ
	- [ ] Implementation makes test pass ‚úÖ
	- [ ] Code is clean ‚úÖ
	- [ ] TDD discipline maintained ‚úÖ
	- [ ] Commit message ready
	
	**Next:** What's the next smallest testable piece?
																		**‚ö†Ô∏è Process Police Alert:** User should intervene if TDD discipline breaks!
															
```


If you notice the agent making changes without test driving, making sprawling edits, or otherwise breaking the rules of engagement then the model has lost context and you need to stop it and reign it back in.

Stop the thread. Tell it what you observe happening. Repost the 3 prompts. Tell it to proceed.


---

## License & Attribution

This template is part of the Human-AI PDCA Collaboration Process framework.

**License:** [Creative Commons Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)

**Attribution:** Process framework developed by [Ken Judy](https://github.com/kenjudy) with Claude Anthropic 4

**Usage:** You are free to use, modify, and distribute this template with appropriate attribution. 

**Source:** [Human-AI Collaboration Process Repository](https://github.com/kenjudy/human-ai-collaboration-process)

---
*2025*